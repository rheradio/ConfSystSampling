---
title: "Q5: SFpC's reliability"
author: "Ruben Heradio (rheradio@issi.uned.es)"
date: "Date: `r Sys.Date()`"
output:
  html_document:
    toc: true
    number_sections: true
    theme: journal
bibliography: references.bib    
csl: ieee.csl     
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning=FALSE)
```

# Summary

TTwo criteria are typically used for assessing measurement quality [@Trochim15]: *validity* and *reliability*. Since we are interested in the quality of SFpC measurements, *validity* will refer to what extent SFpC actually measures uniformity, and *reliability* will refer to repeatability, i.e., to the consistency of the results obtained when SFpC is applied several times to the same sampler and model. **This report examines SFpC's reliability** with a *test-retest* strategy by comparing its results with the sample sets S2 and S3. Both sets include a sample for each sampler and model in the benchmark.


+ S2 is avaiblate at: <a href="https://doi.org/10.5281/zenodo.5509947"><img src="https://zenodo.org/badge/DOI/10.5281/zenodo.5509947.svg" alt="DOI"></a>
+ S3 is avaiblate at: <a href="https://doi.org/10.5281/zenodo.5509947"><img src="https://zenodo.org/badge/DOI/10.5281/zenodo.5509947.svg" alt="DOI"></a>

# Initialization: Importing packages and installing them if needed

```{r package_import, results='hide', warning=FALSE}
REQUIRED_PACKAGES <- 
  c("tidyverse", "irr")
lapply(
  REQUIRED_PACKAGES,
  function(pkg) {
    print(pkg)
    if (system.file(package = pkg) == "") {
      install.packages(pkg,
                       repos = "http://cran.us.r-project.org"
      )
    }
    do.call("library", list(pkg))
  }
)
```
```{r}
sessionInfo()
```

```{r global-constants-and-variables-initialization}
S2_DIR <- "../S2/"
S3_DIR <- "../S3/"
```

# Does SFpC produce reliable results?

```{r }
S2_results <- read.csv(str_c(S2_DIR, "goodness_of_fit.csv"), sep=";")
S3_results <- read.csv(str_c(S3_DIR, "pvalues.csv"), sep=";")

all_validity_results <- tibble(
  sfpc1 = c(
    S2_results$bdd_p_value,
    S2_results$kus_p_value,
    S2_results$quicksampler_p_value,
    S2_results$smarch_p_value,
    S2_results$spur_p_value,
    S2_results$unigen2_p_value
  ),
  sfpc2 = c(
    S3_results$bdd_satdist_p,
    S3_results$kus_satdist_p,
    S3_results$quicksampler_satdist_p,
    S3_results$smarch_satdist_p,
    S3_results$spur_satdist_p,
    S3_results$unigen2_satdist_p
  )
)

# p-values correlation
writeLines("Assessing the p-values' correlation")
writeLines("Pearson correlation coefficient")
cor(all_validity_results$sfpc1, 
    all_validity_results$sfpc2, 
    use = "complete.obs")

# nominal consistency 
writeLines("Assessing the consistency of the uniformity verdict")
all_validity_results <- 
  modify(all_validity_results[1:2], 
       ~ ifelse(.x <= 0.01, 0, 1))
agree(all_validity_results, tolerance=0)
kappa2(all_validity_results)
```


# References